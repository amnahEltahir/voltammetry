{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of out-of-probe model\n",
    "This data set contains data already partitioned, with the training data of 9 probes and the test data\n",
    "from an independent probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import voltammetry\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import r2_score\n",
    "from recordclass import recordclass\n",
    "# load data \n",
    "LABS_out_of_probe_data = h5py.File('pool_uncorrelated_100k_97Hz_25_DA_5HT_pH_WS_1500_TSS_125_CF45.h5','r')\n",
    "training_vgrams = LABS_out_of_probe_data['training/vgrams']\n",
    "training_labels = LABS_out_of_probe_data['training/labels']\n",
    "testing_vgrams = LABS_out_of_probe_data['testing/vgrams']\n",
    "testing_labels = LABS_out_of_probe_data['testing/labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to build the models [ for brevity, only use alpha 1.0]\n",
    "def build_ensemble(vgrams, labels):\n",
    "    # initialize variables\n",
    "    model_array = []\n",
    "    training = recordclass('training','labels, vgrams')\n",
    "    # define bin limits\n",
    "    lim_DA = [900,1800,2700] # max in nanomoles\n",
    "    lim_5HT = [900,1800,2700] # max in nanomoles\n",
    "    bins = [(0,0)] # starting concentration limits\n",
    "    bin_count = 0 # number of bins starting from 0 - 9\n",
    "    # loop through serotonin bins\n",
    "    for i, c_5HT in enumerate(lim_5HT):\n",
    "        # define the maximum and minimum concentrations for iteration\n",
    "        if i == 0:\n",
    "            c_5HT_min = -0.0001\n",
    "            c_5HT_max = c_5HT\n",
    "        else:\n",
    "            c_5HT_min = lim_5HT[i-1]\n",
    "            c_5HT_max = c_5HT\n",
    "        # loop through dopamine concentrations\n",
    "        for j, c_DA in enumerate(lim_DA):\n",
    "            if j == 0:\n",
    "                c_DA_min = -0.0001\n",
    "                c_DA_max = c_DA\n",
    "            else:\n",
    "                c_DA_min = lim_DA[j-1]\n",
    "                c_DA_max = c_DA\n",
    "            print(''.join(('bin: ',str(int(bin_count)),\n",
    "                           ' | DA [',str(int(c_DA_min)),',',str(int(c_DA_max)),\n",
    "                           '] | 5-HT [',str(int(c_5HT_min)),',',str(int(c_5HT_max)),']')))\n",
    "            # select data within concentration bin\n",
    "            idx = np.squeeze(np.where((labels[:,0] > c_DA_min) &\n",
    "                                     (labels[:,0] <= c_DA_max) &\n",
    "                                     (labels[:,1] > c_5HT_min) &\n",
    "                                     (labels[:,1] <= c_5HT_max)))\n",
    "            training.labels = np.squeeze(labels[idx,:])\n",
    "            training.vgrams = np.squeeze(vgrams[idx,:])\n",
    "            training.labels = training.labels[::25,:]\n",
    "            training.vgrams = training.vgrams[::25,:]\n",
    "            # Build models for model array\n",
    "            # bestAlpha = voltammetry.best_alpha(training,parallel=40) #~ in HPC application\n",
    "            bestAlpha = 1.0\n",
    "            cvFit = voltammetry.train_analyte(training, alpha=bestAlpha,parallel=8)\n",
    "            model_array.append(cvFit)\n",
    "            bins.append((c_DA,c_5HT))\n",
    "            bin_count = bin_count +1\n",
    "    \n",
    "    return model_array, bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to search match models to the testing data\n",
    "def ensemble_predictions(vgrams,labels,model_array):\n",
    "    # initialize variables\n",
    "    predictions = np.zeros((np.shape(labels)[0],np.shape(labels)[1]))\n",
    "    testing = recordclass('testing', 'labels, vgrams')\n",
    "    testing_bin = np.empty((9))\n",
    "    b_count = 0\n",
    "    # loop through serotonin bins\n",
    "    for i, c_5HT in enumerate(lim_5HT):\n",
    "        # define the maximum and minimum concentrations for iteration\n",
    "        if i == 0:\n",
    "            c_5HT_min = -0.0001\n",
    "            c_5HT_max = c_5HT\n",
    "        else:\n",
    "            c_5HT_min = lim_5HT[i-1]\n",
    "            c_5HT_max = c_5HT\n",
    "        # loop through dopamine concentrations\n",
    "        for j, c_DA in enumerate(lim_DA):\n",
    "            if j == 0:\n",
    "                c_DA_min = -0.0001\n",
    "                c_DA_max = c_DA\n",
    "            else:\n",
    "                c_DA_min = lim_DA[j-1]\n",
    "                c_DA_max = c_DA\n",
    "            print(''.join(('Predicting bin: ',str(int(bin_count)),\n",
    "                           ' | DA [',str(int(c_DA_min)),',',str(int(c_DA_max)),\n",
    "                           '] | 5-HT [',str(int(c_5HT_min)),',',str(int(c_5HT_max)),']')))\n",
    "            # select data within concentration bin\n",
    "            idx = np.squeeze(np.where((labels[:,0] > c_DA_min) &\n",
    "                                     (labels[:,0] <= c_DA_max) &\n",
    "                                     (labels[:,1] > c_5HT_min) &\n",
    "                                     (labels[:,1] <= c_5HT_max)))\n",
    "            testing.labels = np.squeeze(labels[idx,:])\n",
    "            testing.vgrams = np.squeeze(vgrams[idx,:])\n",
    "            # iterate through model array to find best model\n",
    "            pred_list = []\n",
    "            for k, cvFit in enumerate(model_array):\n",
    "                # generate predictions\n",
    "                pred = np.squeeze(voltammetry.test_analyte(testing,cvFit))\n",
    "                pred_list.append(pred)\n",
    "                # calculate error eij with respect to bin\n",
    "                mean_DA = (c_DA_min + c_DA_max)/2\n",
    "                mean_5HT = (c_5HT_min + c_5HT_max)/2\n",
    "                err_cv[i] = np.sum((pred[:,0] - mean_DA)**2,axis=0) + np.sum((pred[:,1]-mean_5HT)**2,axis=0)\n",
    "            # identify model with minimum error\n",
    "            min_err_idx = np.argmin(err_cv)\n",
    "            print(min_err_idx)\n",
    "            cvFit = cvFitList[min_err_idx]\n",
    "            predictions[idx,:] = pred_list[min_err_idx]\n",
    "\n",
    "            mdl_select_bin[b_count] = min_err_idx\n",
    "            b_count = b_count + 1\n",
    "    return predictions, mdl_select_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression of predictions with known values.\n",
    "# Return figure, 3 axes for dopamine, serotonin and pH.\n",
    "def plot_regr(true_val,predictions):\n",
    "    # initialize plotting variables\n",
    "    fig, ax = plt.subplots(1,3,dpi=100,figsize=(6,3))\n",
    "    x = true_val\n",
    "    y = predictions\n",
    "    analytes=['dopamine','serotonin','pH']\n",
    "    analyte_colors = ['#1f77b4','#b49e1f','#3ebd30']\n",
    "    xlim = [(-.500,3.200),(-.500,3.200),(6.6,8.0)]\n",
    "    ylim = xlim\n",
    "    textLoc = [(0.5,2.800),(0.5000,2.800),(6.9,7.9)]\n",
    "    linlim = [(0,2.700),(0,2.700),(6.8,7.8)]\n",
    "    for chemIx in range(len(analytes)):\n",
    "        labColor = analyte_colors[chemIx]\n",
    "        steps = np.unique(x[:,chemIx]) # unique concentrations\n",
    "        mean_val = np.empty(len(steps))\n",
    "        stdv_val = np.empty(len(steps))\n",
    "        # calculate mean and stdev at each concentration\n",
    "        for i,val in enumerate(steps):\n",
    "            idx = np.where(x[:,chemIx]==val)\n",
    "            mean_val[i] = np.mean(y[idx,chemIx])\n",
    "            stdv_val[i] = statistics.stdev(y[idx,chemIx][0,:,0])\n",
    "        # calculate line of best fit\n",
    "        [m,b] = np.polyfit(x[:,chemIx],y[:,chemIx],1)\n",
    "        # plot line of best fit\n",
    "        ax[chemIx].plot(linlim[chemIx],m*linlim[chemIx]+b,'k',\n",
    "                        label=''.join(('y=','{:.3}'.format(m[0]),'*x+','{:.3f}'.format(b[0]))))\n",
    "        r2 = r2_score(x[:,chemIx],y[:,chemIx])\n",
    "        # plot mean and standard deviation by concentration\n",
    "        ax[chemIx].errorbar(steps,mean_val,yerr=stdv_val,color=labColor,fmt='.',label='Mean $\\pm$ StDev')\n",
    "        # format plot\n",
    "        ax[chemIx].text(textLoc[chemIx][0],textLoc[chemIx][1],''.join(['R$^2$=''{0:.3f}'.format(r2)]))\n",
    "        ax[chemIx].set_xlabel(''.join(['known ',analytes[chemIx],r' $({\\rm\\mu M})$']))\n",
    "        ax[chemIx].set_ylabel(''.join(['predicted ',analytes[chemIx],r' $({\\rm\\mu M})$']))\n",
    "        ax[chemIx].set_xlim(xlim[chemIx])\n",
    "        ax[chemIx].set_ylim(ylim[chemIx])\n",
    "        ax[chemIx].legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "    # format axis for pH units\n",
    "    ax[2].set_ylabel(''.join(['prediction ',analytes[chemIx],' (pH)']))\n",
    "    ax[2].set_xlabel(''.join(['known ',analytes[chemIx],' (pH)']))\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model selection\n",
    "def mdl_select(mdl_select_bin):\n",
    "    # initialize grid\n",
    "    fig,ax = plt.subplots(dpi=100)\n",
    "    gl = [0.9,0.9,0.9] # grid color\n",
    "    #ax.imshow(0.9*np.ones((3,3)),cmap='gray')# draw grid\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    for i in range(len(testing_bin)):\n",
    "        data_bin = i\n",
    "        mdl_bin = mdl_select_bin[i]\n",
    "        # fill in the selected model bin for the test data\n",
    "        ax.fill_between([data_bin,data_bin+1],[md_bin,md_bin+1])\n",
    "        ax.plot([i,i],[0,9],color=gl)\n",
    "        ax.plot([0,9],[i,i],color=gl)\n",
    "    ax.plot([0,9],[9,9],color=gl)\n",
    "    ax.plot([9,9],[0,9])\n",
    "    ax.set_xlabel('test data bin')\n",
    "    ax.set_ylabel('selected model bin')\n",
    "    return fig,ax\n",
    "        \n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, the training data from nine of the ten probes are partitioned according to concentration [900 nM DA X 900 nM 5-HT] and EN-penalized regression is used to generate models within each bin.\n",
    "\n",
    "For the purposes of saving computational resources and time in this demo, only $\\alpha$ of 1.0 will be used. The training data will also be downsampled to by a factor of 25. If performing on a full data set, it is recommended to use a high performance computing cluster with multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to plot results# run  ensemble model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funciton to plot model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin: 0 | DA [0,900] | 5-HT [0,900]\n"
     ]
    }
   ],
   "source": [
    "# run  ensemble model on data\n",
    "[model_array,bins] = build_ensemble(training_vgrams,training_labels)\n",
    "# generate predictions\n",
    "[predictions,mdl_select_bin] = ensemble_predictions(testing_vgrams,testing_labels,model_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results as regression of known and predicted values\n",
    "[reg_fig,reg_ax] = plot_regr(testing_labes,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the relationship between model and test data bins\n",
    "for i,b in enumerate(bins):\n",
    "    print('bin ',i,':',b)\n",
    "[fig_map,ax_map] = mdl_select(mdl_select_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credits\n",
    "import sys, platform, time\n",
    "print('This data demo was created using:')\n",
    "print('Python Version:',sys.version)\n",
    "print('Operating System:',platform.system(),'Version',platform.release())\n",
    "print('GLMnet for python: https://web.stanford.edu/~hastie/glmnet_python/')\n",
    "print('Numpy: https://numpy.org/')\n",
    "print('h5py: http://www.h5py.org/')\n",
    "print('pyplot: https://matplotlib.org/index.html')\n",
    "print('sklearn: https://scikit-learn.org/stable/')\n",
    "print('recordclass: https://pypi.org/project/recordclass/')\n",
    "print('Last updated:',time.strftime('%d-%b-%Y %H:%M:%S',time.localtime()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltammetry",
   "language": "python",
   "name": "voltammetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
